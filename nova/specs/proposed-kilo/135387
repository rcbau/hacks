From 8235255bbaf7fef1808a56d7eea4a2e229331566 Mon Sep 17 00:00:00 2001
From: abhishekkekane <abhishek.kekane@nttdata.com>
Date: Wed, 12 Nov 2014 11:54:08 -0800
Subject: [PATCH] Improve performance of UnShelve API

The aim of this feature is to improve the performance of unshelve
instance by eliminating downloading/copying snapshot time. All
instance files will be retained in the instance store backed by NFS
on the compute node when an instance is shelved.

Change-Id: I2476574f664f5a87a51bec5fac344c839e14b6d1
---
 .../kilo/approved/improve-unshelve-performance.rst | 269 +++++++++++++++++++++
 1 file changed, 269 insertions(+)
 create mode 100644 specs/kilo/approved/improve-unshelve-performance.rst

diff --git a/specs/kilo/approved/improve-unshelve-performance.rst b/specs/kilo/approved/improve-unshelve-performance.rst
new file mode 100644
index 0000000..ff2a893
--- /dev/null
+++ b/specs/kilo/approved/improve-unshelve-performance.rst
@@ -0,0 +1,269 @@
+========================================
+Improve performance of unshelve instance
+========================================
+
+https://blueprints.launchpad.net/nova/+spec/improve-unshelve-performance
+
+The aim of this feature is to improve the performance of unshelve instance
+by eliminating downloading/copying snapshot time. All instance files will be
+retained in the instance store backed by NFS on the compute node when an
+instance is shelved.
+
+Problem description
+===================
+
+When you unshelve hundreds of instances at the same time, instance spawning
+time varies and it mainly depends on the size of the instance snapshot and
+the network speed between glance and nova servers.
+If you have configured file store (NFS) as a backend in Glance for storing
+images/snapshots, then it’s possible to improve the performance of unshelve
+instance dramatically by configuring nova.image.download.FileTransfer in nova.
+In this case, it simply copies the instance snapshot as if it is stored on
+the local filesystem of the compute node. But then again in this case, it is
+observed the network traffic increases enormously between NFS servers and nova
+resulting in slow spawning of the instances.
+
+Use Cases
+----------
+
+Unshelve hundreds of instances in minimal time.
+
+Project Priority
+-----------------
+
+High
+
+Proposed change
+===============
+
+NFS will be used for storing instance files on the compute nodes.
+
+An existing configuration parameter “shelved_offload_time" will be used here
+to indicate the instance files should not be deleted.
+
+-1, never offload: In this case disks are not removed, but the instance is
+shutdown so CPU and Memory are released back to the hypervisor.
+Quotas are not released.
+
+0, offload during shelved: In this case everything is released during the
+shelving process. Quotas are not released.
+
+> 0, offload using “_poll_shelved_instances” periodic task: In this case
+CPU and Memory are released, and the disk is removed later using periodic
+task. Quotas are not released.
+
+New value will be added:
+-2, offload partially, release CPU/Memory but retain instance files.
+
+A new VM state 'SHELVED_PARTIAL_OFFLOADED' and new Task state
+'SHELVING_PARTIAL_OFFLOADING' will be added. In case of SHELVE_OFFLOAD,
+all the resources will be already cleaned up from the compute node so at the
+api layer it only releases network/volume resources consumed by the instance
+when it is deleted in the shelved_offload state. But when shelved_offload_time
+is set to -2, instance files are still persisting on the compute node (NFS)
+and these files needs to be cleanup when the instance is destroyed. To decide
+whether or not terminate instance call should be sent to the compute node,
+there is a need to introduce 'SHELVED_PARTIAL_OFFLOADED' new VM state.
+
+Note: In case shelved_offload_time=-2, You must configure instance path on
+NFS either on all of the compute nodes or group of compute nodes defined
+by host aggregate.
+
+HostAggregate group configuration scenarios:
+1. No HostAggregate groups are configured:
+Administrator hasn't defined any host aggregate groups and the instance path
+is mounted on NFS on all of the compute nodes.
+
+2. HostAggregate groups configured and share same NFS:
+Administrator has defined host aggregate groups for segregating compute nodes
+based on image properties by using AggregateImagePropertiesIsolation filter
+(windows/ubuntu/RHEL etc) and instance types by using
+AggregateInstanceExtraSpecs filter. Compute nodes added to each host
+aggregate group uses its own NFS.
+
+3. HostAggregate groups configured with same properties on multiple NFS:
+Everything is same as scenario #2 but in this case to address scalability
+issue of NFS servers (There is a capacity limitation on each NFS Server),
+administrator will create multiple host aggregate group with same
+metadata properties.
+
+For 1st and 2nd scenario, there is no need to change the scheduler logic as
+all compute nodes are sharing the same NFS server. But in the 3rd scenario
+as multiple NFS servers are configured, we need to implement the new scheduler
+logic, for allocating the virtual machine on the host aggregate in which
+instance was previously running. In order to achieve this, while Shelving
+the instance, based on the instance host and store it in the instance
+system metadata. While Unshelving the instance retrieve the
+'host aggregate group id' from instance system metadata and set the same to
+scheduler filter_properties and pass these filter_properties to
+select_destination method of scheduler to select the appropriate host to
+start the instance. We need to implement new scheduling filter
+'HostAggregateGroupFilter' which can filter the host on the basis of
+'host aggregate group id' stored in the filter_properties.
+
+Shelve api call:
+* shelved_host (host where the instance is running) will be set to
+instance_system_metadata.
+* Disk resources (instance files) will not be destroyed
+(self.driver.destroy(…,destroy_disks=False).
+* As disk resources are persisted, instance snapshot will not be taken.
+* CPU/Memory will be released.
+* Store 'host aggregate group id' in instance system metadata.
+* Instance host and node will be set to None.
+* VM state will be set to SHELVED_PARTIAL_OFFLOADED.
+* Quotas will not be released, similar to shelve/shelve_offloaded case.
+
+Note: In case of the host aggregate deployment strategy, decision cannot be
+made by the compute api whether to create a image or not as
+shelved_offload_time parameter will be configured only on the compute nodes,
+so image creation code will be moved from compute api to compute manager.
+
+Unshelve api call:
+* If 'host aggregate group id' is present in instance system metadata,
+then set it to filter_properties.
+* Select a new compute node (nova-scheduler) from the available pool of
+compute nodes
+* Set the newly elected host to the instance and call start_instance method
+(hard reboot). In this case, it will use the already existing instance files
+as it is without the need of downloading/copying instance snapshot from the
+glance server.
+* VM state will be set to ACTIVE.
+* Quotas will not be touched.
+
+Deleting instance in shelve_partial_offload state:
+* Instance host stored in the 'shelved_host' from instance system_metadata
+will be retrieved and assign to the instance.
+* Instance will be destroyed from the shelved host. It will ensure instance
+files are deleted properly.
+* Quotas will be released in the normal workflow.
+
+Advantages:
+* Improve unshelve instance performance as it completely eliminates the need
+of downloading/copying instance snapshot from glance
+* Unshelve instance performance will not be impacted by any kind of backed
+store configured in glance.
+* CPU/Memory released after shelving instances will allow nova scheduler to
+use the compute capacity for launching new instances (similar to
+shelve_offload case).
+* Improve shelve instance performance as it completely eliminates the need
+of taking snapshot and uploading it to glance.
+
+Alternatives
+------------
+
+None
+
+Data model impact
+-----------------
+
+None
+
+REST API impact
+---------------
+
+None
+
+Security impact
+---------------
+
+None
+
+Notifications impact
+--------------------
+
+New notification 'shelve_partial_offload.start' and
+'shelve_partial_offload.end' will be added.
+
+Other end user impact
+---------------------
+
+None
+
+Performance Impact
+------------------
+
+* Shelve instance performance will be improved as snapshot will not be taken
+  when shelve_offload_time is set to -2.
+* Unshelve instance performance will be improved in case instance files are
+  stored on NFS on the compute nodes when shelve_offload_time is set to -2.
+
+Other deployer impact
+---------------------
+
+An existing configuration parameter “shelved_offload_time" will be modified
+here to indicate the instance files shouldn’t be deleted.
+
+-1, never offload
+0, offload when shelved
+> 0, offload using “_poll_shelved_instances” periodic task
+
+New value will be added
+-2, offload partially, release CPU/Memory but retain instance files
+
+Note: In case shelved_offload_time=-2, You must configure instance path on
+NFS either on all of the compute nodes or group of compute nodes defined
+by host aggregate.
+
+If HostAggregate groups configured with same properties on multiple NFS, then
+add 'HostAggregateGroupFilter' in the 'scheduler_default_filters'
+configuration parameter as mentioned below:
+scheduler_default_filters=HostAggregateGroupFilter,AvailabilityZoneFilter,...
+
+Developer impact
+----------------
+
+None
+
+
+Implementation
+==============
+
+Assignee(s)
+-----------
+
+Primary assignee:
+  abhishekkekane
+
+Other contributors:
+  None
+
+Work Items
+----------
+
+* Implement shelve partial offloading
+* Implement unshelve the partial offloaded instance
+* Add unit tests for code coverage
+
+
+Dependencies
+============
+
+Bug: https://bugs.launchpad.net/nova/+bug/1307791
+Patch : https://review.openstack.org/#/c/89298/
+
+
+Testing
+=======
+
+Existing tests will be modified to cover the shelve_offload_partial case.
+
+* tempest/api/compute/servers/test_delete_server.py:
+  def test_delete_server_while_in_shelved_state(self)
+
+* tempest/api/compute/servers/test_server_actions.py:
+  def test_shelve_unshelve_server(self)
+
+* tempest/api/compute/v3/servers/test_server_actions.py:
+  def test_shelve_unshelve_server(self)
+
+
+Documentation Impact
+====================
+
+Please refer 'Other deployer impact' section.
+
+
+References
+==========
+
+None
-- 
1.9.1

