From f56a610283103587217588901eee7b96ad90617f Mon Sep 17 00:00:00 2001
From: Mike Perez <thingee@gmail.com>
Date: Tue, 1 Jul 2014 01:23:06 -0700
Subject: [PATCH] Configurable Virtio-scsi controller settings

Allow max_sectors and cmd_per_lun to be set on guests for the
virtio-scsi controller. This also introduces vHost-SCSI which can take
great advantage of these settings.

Change-Id: I8008dc0e21cc909fb8f08f85aa3e022cc0df5b98
---
 specs/kilo/approved/virtio-scsi-settings.rst | 233 +++++++++++++++++++++++++++
 1 file changed, 233 insertions(+)
 create mode 100644 specs/kilo/approved/virtio-scsi-settings.rst

diff --git a/specs/kilo/approved/virtio-scsi-settings.rst b/specs/kilo/approved/virtio-scsi-settings.rst
new file mode 100644
index 0000000..04aa77a
--- /dev/null
+++ b/specs/kilo/approved/virtio-scsi-settings.rst
@@ -0,0 +1,233 @@
+..
+ This work is licensed under a Creative Commons Attribution 3.0 Unported
+ License.
+
+ http://creativecommons.org/licenses/by/3.0/legalcode
+
+============================================
+Add vHost and additional virtio-scsi options
+============================================
+
+https://blueprints.launchpad.net/nova/+spec/virtio-scsi-settings
+
+This proposal is for providing additional options with Virtio-SCSI via the
+LibvirtConfigGuestController so Nova can have more fine tunable settings for
+Virtio-SCSI.
+
+* `queues` controls the number of virtio queues that are available to an
+  individual virtio-scsi PCI controller instance.  The usage scenario for
+  queues is increased parallelism for adding + removing virtio vring
+  elements, that can result in higher performance when the underlying storage
+  is not limited by how quickly a single virtio queue can process requests.
+  When the backend storage is faster than what a single virtio queues can
+  process, then using a queues > 1 makes sense.
+
+* `cmd_per_lun` is exposed through the Virtio-SCSI configuration registers to
+  the guest, which determines the number of outstanding I/Os per LUN that the
+  guest SCSI subsystem is allowed to keep in flight at a single time. The usage
+  scenario for cmd_per_lun is to allow an individual virtio-scsi PCI controller
+  instance to limit the maximum number of I/Os in flight at a given time. By
+  default, virtio-scsi uses cmd_per_lun = 1024. Reducing cmd_per_lun can be
+  useful when an individual controller (or guest) needs to be limited in the
+  number of outstanding I/O it can generate for QoS purposes.
+
+* `max_sectors` is exposed through the Virtio-SCSI configuration registers to
+  the guest, which determines the number of sectors per I/O (eg: total size per
+  I/O) that the guest SCSI subsystem is allowed to send for a single I/O
+  request. The usage scenario for max_sectors is to allow an individual
+  virtio-scsi PCI controller instance to limit the maximum size of individual
+  I/O requests being generated by the guest. By default, virtio-scsi uses
+  max_sectors = 0xFFFF. Reducing max_sectors can be useful when dealing with
+  storage devices that have difficulty keeping up with large I/O requests, but
+  breaking them up into smaller max_sectors * sector_size chunks.
+
+* Building on top of Virtio-SCSI with vHost-SCSI for better performance with
+  attached devices to guests. vHost can also take advantage of the options
+  listed above and is supported in both the Linux kernel and qemu. vHost is
+  a target to a LUN. The block device that is under the LUN is exported
+  locally on the compute node. Since vHost is a target created locally,
+  migration must be handled outside of QEMU with any number of solutions that
+  allow you expose a block device to another host (e.g. ISCSI), and create
+  a new vHost endpoint at the new host.
+
+  Along with the performance benefits, vhost-scsi is the only way to expose
+  guest T10 protection information (DIF) to the host. This is because there is
+  currently no user space interface to attach T10 PI to a read/write i/o
+  request.  This means that any future virtio-scsi data plane effort will not
+  be able to support end-to-end data protection until such a user space
+  interface is merged into the upstream kernel. vhost-scsi already supports T10
+  PI starting with the 3.16 kernel. [1][2][3]
+
+* `wwpn` is the vHost endpoint. When vHost is used, wwpn will be a required
+  attribute to be set in the LibvirtConfigGuestController. An example of an
+  endpoint looks like `naa.60014050a13df4f2`.
+
+
+Problem description
+===================
+
+Virtio-SCSI comes with additional configuration options that would allow users
+to fine tune how a block device is used by a virtual machine. The options
+listed above: queues, cmd_per_lun and max_sectors are features that are
+available in Virtio-SCSI today. The ability to configure guest controllers was
+added in the Juno release [4]. The additional settings available in QEMU and
+exposed by libvirt [5].
+
+In addition to Virtio-SCSI, vHost-SCSI takes advantage of the same options, but
+provides even greater performance [6]. The vHost driver was added in the 3.6
+Linux kernel. It provides virtually bare-metal local storage performance for
+KVM guests. The vHost driver is not a self-contained virtio device, as it
+depends on userspace to handle the control plane while the data plane is done
+in kernel.
+
+This means the data plane does not go through host user-space process context,
+and the individual KVM guest virtio ring elements are processed and dispatched
+into LIO fabric driver code from within KVM host kernel-space.  [6]
+
+The vHost host kernel driver is not a self-contained virtio device, and depends
+upon QEMU v1.6+ userspace for para-virtualized virtio-scsi PCIe device control
++ data queue emulation.  QEMU accesses the vhost kernel endpoints through
+a /dev/vhost-scsi IOCTL interface used for configuring vhost level memory
+access, and attach/detach of vhost-scsi WWPN controllers into KVM guest.
+
+Use Cases
+----------
+
+* Low (sub 100 usec) latencies for AIO reads/writes with small iodepth
+  workloads.
+* 1M+ small block IOPs workloads at low CPU utilization with large iopdeth
+  workloads.
+* End-to-end data integrity using T10 protection information (DIF).
+
+Project Priority
+-----------------
+
+None
+
+Proposed change
+===============
+
+These settings will be set by the administrator only via Cinder's volume types.
+Cinder's vHost connector [7] will make attempts of looking for these settings
+specified to send in addition to the target_wwpn to Nova.
+
+Since virtio-scsi only looks for these settings from the SCSI host [8], each
+volume attach Nova does will be creating a new controller with these settings
+on the instance to attach the device with.
+
+
+Alternatives
+------------
+
+n/a
+
+Data model impact
+-----------------
+
+n/a
+
+REST API impact
+---------------
+
+n/a
+
+Security impact
+---------------
+
+n/a
+
+Notifications impact
+--------------------
+
+n/a
+
+Other end user impact
+---------------------
+
+n/a
+
+Performance Impact
+------------------
+
+vhost-scsi is an optimized I/O path for virtio-scsi guests.  It avoids
+second-level host user-space AIO+O_DIRECT overheads by accessing KVM guest
+virtio ring elements directly from within KVM host kernel context.  It provides
+increased performance and reduced latency under heavy small block random I/O
+workloads as the total number of KVM guest virtio-scsi controllers and LUNs
+increases.
+
+Other deployer impact
+---------------------
+
+These features are completely optional for the administrator to enable. If the
+administrator chooses to enable these features for certain storage backends,
+they can be set in volume types that are mapped to certain Cinder volume
+drivers that are making use of the vHost connector provided by Cinder. Each
+volume that Nova requests Cinder for connection data, Cinder will look to see
+if these settings are set by the administrator, and provide them with the
+connection data to Nova to set in the guest controller.
+
+Developer impact
+----------------
+
+n/a
+
+Implementation
+==============
+
+Assignee(s)
+-----------
+
+Primary assignee:
+    thingee
+
+Work Items
+----------
+
+* Libvirt patch merged to expose `queues`, `cmd_per_lun` and `max_sectors`.
+* vHost connector in Cinder. This was originally approved for Juno, but will
+  move to Kilo.
+* New libvirt volume class to accept connection data from Cinder.
+
+Dependencies
+============
+
+Linux v3.6+ host kernel with LIO target + vhost-scsi fabric support
+Linux v3.6+ guest kernel with virtio-scsi LLD support with the following
+bugfix:
+
+[SCSI] virtio-scsi: Add vdrv->scan for post VIRTIO_CONFIG_S_DRIVER_OK LUN
+scanning [9]
+
+QEMU v1.6+ with vhost-scsi support enabled
+targetcli and rtslib v3.0 with default vhost-scsi.spec
+Future libvirt version with vhost-scsi support (TODO)
+
+Testing
+=======
+
+Appropriate unit tests will be provided. Gate will likely not have the
+appropriate libvirt/qemu version to do testing in tempest.
+
+Documentation Impact
+====================
+
+Provide similar information on these settings in either Nova, Cinder
+documentation. To better help users, instead of just explaining the options, I
+can provide a few examples for different scenarios of how you would set these
+settings. I would like to add in the operator's guide the set of configurations
+needed in both Nova and Cinder along with the dependency requirements to make
+this all work.
+
+References
+==========
+
+[1] - https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/drivers/scsi/virtio_scsi.c?id=e6dc783a38ec0f2a5a91edda3f76195dffb17a16
+[2] - https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/drivers/vhost/scsi.c?id=e31885dd901e80d5bd528c1cbedde07ebbf051b2
+[3] - https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/drivers/vhost/scsi.c?id=95e7c4341b8e28dae5204378087c1e2a115abc82
+[4] - https://review.openstack.org/#/c/84494/
+[5] - http://libvirt.org/git/?p=libvirt.git;a=commit;h=d950494129513558a303387e26a2bab057012c5e
+[6] - http://linux-iscsi.org/wiki/VHost#Linux_performance
+[7] - https://github.com/openstack/cinder-specs/blob/master/specs/juno/vhost-support.rst
+[8] - https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/drivers/scsi/virtio_scsi.c#n884
+[9] - https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/drivers/scsi/virtio_scsi.c?id=59057fbc37178f10a196ab7ec170b80273f75a47
-- 
1.9.1

